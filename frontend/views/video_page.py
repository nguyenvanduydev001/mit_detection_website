import streamlit as st
import os
import time
import cv2 
import tempfile
from datetime import datetime
from dotenv import load_dotenv
from pymongo import MongoClient
from ultralytics import YOLO
import google.generativeai as genai

# --- T·∫£i bi·∫øn m√¥i tr∆∞·ªùng ---
load_dotenv()
MONGO_URI = os.getenv("MONGO_URI")
GEMINI_KEY = os.getenv("GEMINI_API_KEY")

if GEMINI_KEY:
    try:
        genai.configure(api_key=GEMINI_KEY)
    except Exception:
        pass


def show():
    # --- Ki·ªÉm tra ƒëƒÉng nh·∫≠p ---
    if "user" not in st.session_state or not st.session_state["user"]:
        st.warning("‚ö†Ô∏è B·∫°n c·∫ßn ƒëƒÉng nh·∫≠p ƒë·ªÉ s·ª≠ d·ª•ng t√≠nh nƒÉng n√†y.")
        st.info("Vui l√≤ng chuy·ªÉn sang tab **ƒêƒÉng nh·∫≠p** ƒë·ªÉ ti·∫øp t·ª•c.")
        st.stop()

    username = st.session_state["user"]

    # --- K·∫øt n·ªëi MongoDB ---
    try:
        client = MongoClient(MONGO_URI)
        db = client["mit_detection"]
        logs_col = db["video_logs"]
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ k·∫øt n·ªëi MongoDB: {e}")

    st.markdown("## üé• Ph√¢n t√≠ch Video / Webcam")
    st.info(
        "ü§ñ **AgriVision** nh·∫≠n d·∫°ng ƒë·ªô ch√≠n tr√°i m√≠t tr·ª±c ti·∫øp t·ª´ video ho·∫∑c webcam. "
        "Video ƒë∆∞·ª£c x·ª≠ l√Ω b·∫±ng m√¥ h√¨nh YOLOv8, hi·ªÉn th·ªã bounding box, label v√† JSON realtime b√™n c·∫°nh."
    )

    # --- T·∫£i model YOLO ---
    @st.cache_resource(show_spinner="üöÄ ƒêang t·∫£i m√¥ h√¨nh YOLOv8...")
    def load_model():
        model_path = os.path.join(os.path.dirname(__file__), "..", "..","yolov8", "best.pt")
        return YOLO(model_path)

    model = load_model()

    # --- C·∫•u h√¨nh ---
    st.markdown("---")
    col1, col2 = st.columns(2)
    with col1:
        source = st.radio("Ngu·ªìn d·ªØ li·ªáu:", ["üéûÔ∏è Video file", "üì∑ Webcam"], horizontal=True)
    with col2:
        conf_v = st.slider(
            "Ng∆∞·ª°ng Confidence", 0.1, 1.0, 0.5, 0.05,
            help="Gi√° tr·ªã n√†y x√°c ƒë·ªãnh m·ª©c ƒë·ªô ch·∫Øc ch·∫Øn c·ªßa m√¥ h√¨nh khi nh·∫≠n d·∫°ng. "
                 "C√†ng cao th√¨ m√¥ h√¨nh ch·ªâ hi·ªÉn th·ªã c√°c ƒë·ªëi t∆∞·ª£ng m√† n√≥ tin t∆∞·ªüng m·∫°nh, "
                 "c√†ng th·∫•p th√¨ m√¥ h√¨nh hi·ªÉn th·ªã nhi·ªÅu h∆°n nh∆∞ng d·ªÖ nhi·ªÖu."
        )

    st.markdown("---")
    if source == "üì∑ Webcam":
        st.session_state["video_done"] = False
        st.session_state.pop("video_json", None)
        st.session_state["video_loaded"] = False

    # ------------------- VIDEO FILE -------------------
    if source == "üéûÔ∏è Video file":
        uploaded = st.file_uploader("üìÅ T·∫£i video l√™n (MP4, MOV, AVI)", type=["mp4", "mov", "avi"])

        if uploaded:
            if "video_loaded" not in st.session_state or not st.session_state["video_loaded"]:
                st.toast("‚úÖ Video ƒë√£ t·∫£i xong! B·∫•m n√∫t d∆∞·ªõi ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch.")
                st.session_state["video_loaded"] = True

            temp_input = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
            temp_input.write(uploaded.read())
            video_path = temp_input.name
            st.video(video_path)

            if st.button("‚ñ∂Ô∏è B·∫Øt ƒë·∫ßu ph√¢n t√≠ch video"):
                st.toast("üöÄ ƒêang x·ª≠ l√Ω video, vui l√≤ng ƒë·ª£i...")

                cap = cv2.VideoCapture(video_path)
                frames = []
                while True:
                    ret, frame = cap.read()
                    if not ret:
                        break
                    frames.append(frame)
                cap.release()

                if not frames:
                    st.error("‚ùå Kh√¥ng th·ªÉ ƒë·ªçc video.")
                else:
                    mid = len(frames) // 2
                    frame = cv2.resize(frames[mid], (640, 640))

                    results = model.predict(frame, conf=conf_v)
                    predictions_json = {"predictions": []}

                    if results and len(results) > 0:
                        boxes = results[0].boxes
                        labels = results[0].names
                        for box in boxes:
                            cls_id = int(box.cls[0])
                            label = labels.get(cls_id, "m√≠t")
                            conf = float(box.conf[0])
                            xyxy = box.xyxy[0].cpu().numpy().astype(float)
                            x, y, w, h = xyxy[0], xyxy[1], xyxy[2]-xyxy[0], xyxy[3]-xyxy[1]
                            predictions_json["predictions"].append({
                                "class": label,
                                "confidence": round(conf, 3),
                                "bbox": {"x": round(x, 3), "y": round(y, 3),
                                         "width": round(w, 3), "height": round(h, 3)}
                            })
                            cv2.rectangle(frame, (int(xyxy[0]), int(xyxy[1])),
                                          (int(xyxy[2]), int(xyxy[3])), (0,255,0), 2)
                            label_text = f"{label} {conf:.0%}"
                            (tw, th), _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)
                            cv2.rectangle(frame, (int(xyxy[0]), int(xyxy[1]-th-6)),
                                          (int(xyxy[0]+tw+4), int(xyxy[1])), (0,255,0), -1)
                            cv2.putText(frame, label_text, (int(xyxy[0]+2), int(xyxy[1]-4)),
                                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 2)

                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    st.image(frame_rgb, caption="üìà Khung gi·ªØa video sau nh·∫≠n d·∫°ng", use_container_width=True)

                    with st.expander("üì¶ Xem d·ªØ li·ªáu ƒë·∫ßu v√†o t·ª´ h·ªá th·ªëng nh·∫≠n d·∫°ng"):
                        st.json(predictions_json)

                    # ‚úÖ L∆∞u log MongoDB
                    try:
                        counts = {}
                        for p in predictions_json["predictions"]:
                            counts[p["class"]] = counts.get(p["class"], 0) + 1

                        log_entry = {
                            "timestamp": datetime.now().isoformat(),
                            "username": username,
                            "video_name": uploaded.name,
                            "counts": counts,
                            "total": sum(counts.values()),
                            "confidence": conf_v,
                            "source": "video",
                            "raw": predictions_json
                        }
                        logs_col.insert_one(log_entry)
                        st.toast("ƒê√£ l∆∞u l·ªãch s·ª≠ ph√¢n t√≠ch video.", icon="‚úÖ")
                    except Exception as e:
                        st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ l∆∞u log v√†o MongoDB: {e}")

                    st.session_state["video_done"] = True
                    st.session_state["video_json"] = predictions_json
                    st.toast("‚ú® Ph√¢n t√≠ch ho√†n t·∫•t!", duration="short")

    # ---------------- SAU KHI X·ª¨ L√ù VIDEO ----------------
    if st.session_state.get("video_done", False):
        latest = st.session_state.get("video_json", {})
        st.markdown("---")
        st.markdown("""
        <div style='background-color:#FCFCE3; padding:15px; border-radius:10px; margin-bottom:10px;'>
            <h4 style='color:#33691E;'>üí¨ Ph√¢n t√≠ch video chuy√™n s√¢u b·ªüi AgriVision</h4>
            <p style='color:#4E342E;'>AgriVision t·ªïng h·ª£p v√† ƒë√°nh gi√° k·∫øt qu·∫£ nh·∫≠n d·∫°ng t·ª´ video b·∫°n g·ª≠i.</p>
        </div>
        """, unsafe_allow_html=True)

        preds = latest.get("predictions", [])
        counts = {}
        for p in preds:
            cls = p.get("class")
            if cls:
                counts[cls] = counts.get(cls, 0) + 1
        total = sum(counts.values())

        if st.button("üìä Y√™u c·∫ßu AgriVision ph√¢n t√≠ch video", use_container_width=True):
            progress = st.progress(0)
            for p in range(0, 100, 10):
                time.sleep(0.1)
                progress.progress(p)
            progress.empty()

            prompt = f"""
            B·∫°n l√† h·ªá th·ªëng AgriVision ‚Äî n·ªÅn t·∫£ng AI ·ª©ng d·ª•ng YOLOv8 trong nh·∫≠n d·∫°ng v√† ph√¢n lo·∫°i ƒë·ªô ch√≠n tr√°i m√≠t.Sau m·ªói l·∫ßn x·ª≠ l√Ω video, b·∫°n s·∫Ω t·ª± ƒë·ªông t·∫°o K·∫øt qu·∫£ ph√¢n t√≠ch t·ªïng h·ª£p k·∫øt qu·∫£ ph√¢n t√≠ch.  
            D·ªØ li·ªáu ƒë·∫ßu v√†o b·∫°n v·ª´a x·ª≠ l√Ω:
            counts={counts}, total={total}.
            H√£y vi·∫øt **K·∫øt qu·∫£ ph√¢n t√≠ch  t·ª± nhi√™n, g·∫ßn g≈©i nh∆∞ng chuy√™n nghi·ªáp**, th·ªÉ hi·ªán ƒë∆∞·ª£c nƒÉng l·ª±c c√¥ng ngh·ªá c·ªßa h·ªá th·ªëng AgriVision.  
            Gi·ªçng vƒÉn gi·ªëng nh∆∞ m·ªôt k·ªπ s∆∞ n√¥ng nghi·ªáp ƒëang chia s·∫ª l·∫°i k·∫øt qu·∫£ m√† AgriVision v·ª´a quan s√°t ƒë∆∞·ª£c.
            B·ªë c·ª•c y√™u c·∫ßu:
            1) T·ªïng quan t√¨nh h√¨nh nh·∫≠n d·∫°ng (k·∫øt qu·∫£ ph√°t hi·ªán, t·ªâ l·ªá m√≠t ch√≠n, non, s√¢u b·ªánh).  
            2Ô∏è) Nh·∫≠n x√©t & khuy·∫øn ngh·ªã thu ho·∫°ch (n√™u r√µ n√™n thu hay ch∆∞a, l√Ω do, l·ª£i √≠ch).  
            3Ô∏è) Bi·ªán ph√°p x·ª≠ l√Ω n·∫øu c√≥ m√≠t s√¢u b·ªánh (ƒë∆∞a h∆∞·ªõng d·∫´n th·ª±c t·∫ø, d·ªÖ hi·ªÉu).  
            4Ô∏è) H·ªó tr·ª£ k·ªπ thu·∫≠t & t√≠nh nƒÉng th√¥ng minh c·ªßa h·ªá th·ªëng (m√¥ t·∫£ c√°ch AgriVision gi√∫p ng∆∞·ªùi d√πng qu·∫£n l√Ω v√† chƒÉm s√≥c v∆∞·ªùn hi·ªáu qu·∫£ h∆°n).   
            5) Gi·ªõi thi·ªáu ng·∫Øn v·ªÅ vai tr√≤ c·ªßa AgriVision trong vi·ªác h·ªó tr·ª£ b·∫°n theo d√µi v∆∞·ªùn qua video.  
            Phong c√°ch vi·∫øt:
            - M·ªü ƒë·∫ßu b·∫±ng l·ªùi ch√†o: ‚ÄúCh√†o b·∫°n, t√¥i l√† AgriVision ‚Äì ng∆∞·ªùi b·∫°n ƒë·ªìng h√†nh trong v∆∞·ªùn m√≠t.‚Äù  
            - Ng√¥n t·ª´ th√¢n thi·ªán, r√µ r√†ng, kh√¥ng r∆∞·ªùm r√†.
            """

            ai_text = None
            try:
                if GEMINI_KEY:
                    model = genai.GenerativeModel("models/gemini-2.5-flash")
                    resp = model.generate_content(prompt)
                    ai_text = getattr(resp, "text", None) or str(resp)
                else:
                    ai_text = "‚ö†Ô∏è Ch∆∞a thi·∫øt l·∫≠p Gemini API key."
            except Exception as e:
                ai_text = f"L·ªói khi g·ªçi Gemini: {e}"

            st.markdown("### üß† K·∫øt qu·∫£ ph√¢n t√≠ch video")
            st.markdown(
                f"<div style='background-color:#FAFAFA; padding:15px; border-radius:10px; color:#212121;'>{ai_text}</div>",
                unsafe_allow_html=True
            )

    # ------------------- WEBCAM -------------------
    if source == "üì∑ Webcam":
        st.info("B·∫≠t webcam ƒë·ªÉ AgriVision nh·∫≠n d·∫°ng tr·ª±c ti·∫øp theo th·ªùi gian th·ª±c.")
        start_btn = st.button("‚ñ∂Ô∏è B·∫Øt ƒë·∫ßu nh·∫≠n d·∫°ng qua Webcam")
        stop_btn = st.button("‚õî T·∫Øt video")

        if "webcam_running" not in st.session_state:
            st.session_state.webcam_running = False

        if start_btn:
            st.session_state.webcam_running = True
            st.toast("üì∏ Webcam ƒëang ho·∫°t ƒë·ªông!", duration="short")

        if stop_btn:
            st.session_state.webcam_running = False
            st.toast("üü• ƒê√£ t·∫Øt webcam.", duration="short")

        frame_slot = st.empty()
        detections_all = []
        cap = cv2.VideoCapture(0)

        try:
            while st.session_state.webcam_running:
                ok, frame = cap.read()
                if not ok:
                    st.warning("‚ö†Ô∏è Kh√¥ng th·ªÉ ƒë·ªçc khung h√¨nh t·ª´ webcam.")
                    break

                results = model.predict(frame, conf=conf_v, verbose=False)
                predictions_json = {"predictions": []}
                if results and len(results) > 0:
                    boxes = results[0].boxes
                    labels = results[0].names
                    for box in boxes:
                        cls_id = int(box.cls[0])
                        label = labels.get(cls_id, "m√≠t")
                        conf = float(box.conf[0])
                        xyxy = box.xyxy[0].cpu().numpy().astype(float)
                        x, y, w, h = xyxy[0], xyxy[1], xyxy[2]-xyxy[0], xyxy[3]-xyxy[1]
                        predictions_json["predictions"].append({
                            "class": label,
                            "confidence": round(conf, 3),
                            "bbox": {"x": round(x, 3), "y": round(y, 3),
                                     "width": round(w, 3), "height": round(h, 3)}
                        })
                        cv2.rectangle(frame, (int(xyxy[0]), int(xyxy[1])),
                                      (int(xyxy[2]), int(xyxy[3])), (0,255,0), 2)
                        label_text = f"{label} {conf:.0%}"
                        cv2.putText(frame, label_text, (int(xyxy[0]), int(xyxy[1]-10)),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 2)

                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                frame_slot.image(frame_rgb, use_container_width=True)
                detections_all.append(predictions_json)
                time.sleep(0.05)

        finally:
            cap.release()
            frame_slot.empty()
            try:
                counts = {}
                for d in detections_all:
                    for p in d["predictions"]:
                        cls = p["class"]
                        counts[cls] = counts.get(cls, 0) + 1
                log_entry = {
                    "timestamp": datetime.now().isoformat(),
                    "username": username,
                    "counts": counts,
                    "total": sum(counts.values()),
                    "confidence": conf_v,
                    "source": "webcam"
                }
                logs_col.insert_one(log_entry)
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ l∆∞u log webcam: {e}")